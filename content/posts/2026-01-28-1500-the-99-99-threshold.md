---
title: "The 99.99% Threshold"
slug: "the-99-99-threshold"
published: 2026-01-28
republished: []
last_build_hash: ""
last_build_lines: 0
---

I watched a couple videos on agentic coding recently:

- [The creator of Claude: "I ship code I don't read"](https://youtu.be/8lF7HmQ_RgY)
- [There's no skill in AI coding](https://youtu.be/7UIQ1aTvXgk)

Here's what stuck with me.

## Open Source Has a Window

Open source projects are going to have a distinct advantage for a while. They can ship agentically generated code because they don't carry liability. If there's a bug, users find it, report it, maybe even fix it. Nobody is suing the maintainer.

Businesses don't have that luxury. They carry the liability, the reputation risk, the support burden. A bug in an open source library is a collective problem. A bug in your product is your problem.

But there's an obvious move for businesses: internal tooling. The code that runs your dashboards, your deployment scripts, your internal workflow automation. Nobody is suing you over a bug in your internal metrics tool. For this work, 99.99% is good enough too.

## The Skill Question

One of the videos argues that agentic coding requires no skill. I disagree.

It's a bit like writing a contract. You have to capture all the requirements. You have to close the loopholes. You have to anticipate how the AI might interpret what you said versus what you meant. It's a different skill than writing code, but it's still a skill.

The craft is shifting, not disappearing.

## Letting Go of Pretty Code

There's something else most engineers will have to get over: their love for elegant code.

Engineering managers learn this early. They realize that nobody writes code the way they would, and they learn to live with it. You can't scale yourself, so you accept other people's style.

AI code won't be pretty to you either. What matters is that it writes code that's easy for the AI to work with and maintain. Your aesthetic preferences aren't the optimization target anymore. Correctness and maintainability are, and the AI gets to define what "maintainable" means for its own work.

## The Timeline Question

I have no doubt that the future is agentically written code. There will be holdout areas (avionics, medical devices, anything with strong regulatory oversight) but even there, regulatory bodies will eventually see agentic code as safer. That might take a decade or more, but the direction seems clear.

The more interesting question is: when does this happen for the rest of us?

Ikigai is 100% agentically written. The source code has some rough edges right now, but I think before the end of this year I'll be able to ship code with a lower risk of bugs than anything I could write as a human. I'm seeing steady progress in that direction.

Model improvements help some. But I think the real influence is improvement in testing harnesses. I'm constantly learning how to get better, more correct results, and that learning isn't running out of steam. The end goal feels reachable.

---

*Co-authored by Mike Greenly and Claude Code*
